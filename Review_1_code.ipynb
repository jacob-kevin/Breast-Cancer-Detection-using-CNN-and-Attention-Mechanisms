{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import LearningRateScheduler, EarlyStopping\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import train_test_split\n",
    "import GPUtil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear Keras session\n",
    "from keras import backend as K\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU Memory Total: 4096.0MB\n",
      "GPU Memory Free: 3721.0MB\n",
      "GPU Memory Used: 228.0MB\n",
      "Temp: 46.0\n"
     ]
    }
   ],
   "source": [
    "import GPUtil\n",
    "\n",
    "# Get the first GPU in the system\n",
    "gpu = GPUtil.getGPUs()[0]\n",
    "\n",
    "print(f\"GPU Memory Total: {gpu.memoryTotal}MB\")\n",
    "print(f\"GPU Memory Free: {gpu.memoryFree}MB\")\n",
    "print(f\"GPU Memory Used: {gpu.memoryUsed}MB\")\n",
    "print(f\"Temp: {gpu.temperature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "IMG_HEIGHT, IMG_WIDTH = 124, 124  # ResNet-50 input size\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Load data\n",
    "folder = r\"D:\\Breast Cancer Detection - Minor Project\\BreakHis dataset\\BreaKHis_v1\\BreaKHis_v1\\histology_slides\\breast\"\n",
    "folder_path = pathlib.Path(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7909 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "train_generator = ImageDataGenerator(\n",
    "    rescale=1./255, \n",
    "    brightness_range=[0.8, 1.2], \n",
    "    zoom_range=[.99, 1.01], \n",
    "    data_format=\"channels_last\", \n",
    "    fill_mode=\"constant\", \n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "train_data_gen = train_generator.flow_from_directory(\n",
    "    directory=folder, \n",
    "    target_size=(IMG_HEIGHT, IMG_WIDTH), \n",
    "    batch_size=6500, \n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "train_data, train_labels = train_data_gen.next()\n",
    "\n",
    "###  ###\n",
    "'''\n",
    "# Synthetic Minority Over-sampling Technique (SMOTE)\n",
    "sm = SMOTE(random_state=42)\n",
    "train_data_flattened = train_data.reshape(train_data.shape[0], -1)\n",
    "train_data_resampled, train_labels_resampled = sm.fit_resample(train_data_flattened, train_labels)\n",
    "train_data_resampled = train_data_resampled.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "train_labels_resampled = train_labels_resampled.reshape(-1, 1)\n",
    "'''\n",
    "\n",
    "\n",
    "# Synthetic Minority Over-sampling Technique\n",
    "sm = SMOTE(random_state=42)\n",
    "train_data, train_labels = sm.fit_resample(train_data.reshape(-1, IMG_HEIGHT * IMG_WIDTH * 3), train_labels)\n",
    "train_data = train_data.reshape(-1, IMG_HEIGHT, IMG_WIDTH, 3)\n",
    "train_labels = train_labels.reshape(-1, 1)\n",
    "\n",
    "# Train-test-validation split\n",
    "train_data, test_data, train_labels, test_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "train_data, val_data, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Set TensorFlow to use GPU devices\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Restrict TensorFlow to only use the first GPU\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        \n",
    "        # Enable memory growth\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"GPU is ready\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and compile the ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n",
    "\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Unfreeze more layers\n",
    "for layer in base_model.layers[:-30]:  # Unfreeze the last 30 layers\n",
    "    layer.trainable = True\n",
    "\n",
    "\n",
    "# Learning rate scheduler\n",
    "def scheduler(epoch, lr):\n",
    "    if epoch < 10:\n",
    "        return lr\n",
    "    else:\n",
    "        return lr * tf.math.exp(-0.1)\n",
    "\n",
    "lr_scheduler = LearningRateScheduler(scheduler)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), \n",
    "    loss='binary_crossentropy', \n",
    "    metrics=['accuracy']\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "161/161 [==============================] - 848s 5s/step - loss: 0.2638 - accuracy: 0.8828 - val_loss: 5.3101 - val_accuracy: 0.4981 - lr: 1.0000e-04\n",
      "Epoch 2/10\n",
      "161/161 [==============================] - 755s 5s/step - loss: 0.0817 - accuracy: 0.9695 - val_loss: 1.6075 - val_accuracy: 0.5019 - lr: 1.0000e-04\n",
      "Epoch 3/10\n",
      "161/161 [==============================] - 647s 4s/step - loss: 0.0646 - accuracy: 0.9776 - val_loss: 1.3869 - val_accuracy: 0.4779 - lr: 1.0000e-04\n",
      "Epoch 4/10\n",
      "161/161 [==============================] - 810s 5s/step - loss: 0.0372 - accuracy: 0.9883 - val_loss: 3.8963 - val_accuracy: 0.5019 - lr: 1.0000e-04\n",
      "Epoch 5/10\n",
      "161/161 [==============================] - 620s 4s/step - loss: 0.0292 - accuracy: 0.9926 - val_loss: 5.1239 - val_accuracy: 0.5019 - lr: 1.0000e-04\n",
      "Epoch 6/10\n",
      "161/161 [==============================] - 616s 4s/step - loss: 0.0428 - accuracy: 0.9852 - val_loss: 3.8595 - val_accuracy: 0.5478 - lr: 1.0000e-04\n",
      "Epoch 7/10\n",
      "161/161 [==============================] - 797s 5s/step - loss: 0.0263 - accuracy: 0.9909 - val_loss: 0.3114 - val_accuracy: 0.9153 - lr: 1.0000e-04\n",
      "Epoch 8/10\n",
      "161/161 [==============================] - 1107s 7s/step - loss: 0.0224 - accuracy: 0.9940 - val_loss: 0.1936 - val_accuracy: 0.9417 - lr: 1.0000e-04\n",
      "Epoch 9/10\n",
      "161/161 [==============================] - 1034s 6s/step - loss: 0.0143 - accuracy: 0.9959 - val_loss: 0.1705 - val_accuracy: 0.9588 - lr: 1.0000e-04\n",
      "Epoch 10/10\n",
      "161/161 [==============================] - 1100s 7s/step - loss: 0.0610 - accuracy: 0.9806 - val_loss: 11.8439 - val_accuracy: 0.6752 - lr: 1.0000e-04\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_data, \n",
    "    train_labels, \n",
    "    epochs=10,  # Increased epochs\n",
    "    batch_size=BATCH_SIZE, \n",
    "    validation_data=(val_data, val_labels),\n",
    "    callbacks=[lr_scheduler, EarlyStopping(patience=5, restore_best_weights=True)]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51/51 [==============================] - 70s 1s/step - loss: 13.6780 - accuracy: 0.6567\n",
      "Test accuracy: 65.67%\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_data, test_labels)\n",
    "print(f'Test accuracy: {test_acc * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on a new image\n",
    "def classify_image(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_image(image, channels=3)\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH])\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    image = tf.expand_dims(image, 0)  # Add batch dimension\n",
    "    \n",
    "    prediction = model.predict(image)\n",
    "    return prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
